{
  "tasks": [
    {
      "metadata": {
        "task_type": "array_sum",
        "hardware": {
          "cpus": [
            {
              "cores": 12,
              "threads": 32,
              "frequency": "3.6 GHz",
              "available": "True"
            }
          ],
          "gpu": {
            "cuda_cores": 10496,
            "memory": {
              "size": "24 GB",
              "type": "GDDR6X"
            },
            "available": "True"
          }
        },
        "code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void sum_kernel(const long long* arr, long long* partial_sums, int n) {\n    extern __shared__ long long sdata[];\n    \n    int tid = threadIdx.x;\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    \n    // Load data into shared memory\n    sdata[tid] = (i < n) ? arr[i] : 0;\n    __syncthreads();\n    \n    // Perform reduction in shared memory\n    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n        if (tid < s) {\n            sdata[tid] += sdata[tid + s];\n        }\n        __syncthreads();\n    }\n    \n    // Write result for this block to global memory\n    if (tid == 0) {\n        partial_sums[blockIdx.x] = sdata[0];\n    }\n}\n\nlong long array_sum(const Array& arr) {\n    int n = arr.size();\n    if (n == 0) return 0;\n    \n    // GPU memory pointers\n    long long* d_arr = nullptr;\n    long long* d_partial_sums = nullptr;\n    \n    // Calculate optimal block size and grid size\n    int blockSize = 512;\n    int gridSize = (n + blockSize - 1) / blockSize;\n    \n    // Allocate GPU memory\n    cudaMalloc(&d_arr, n * sizeof(long long));\n    cudaMalloc(&d_partial_sums, gridSize * sizeof(long long));\n    \n    // Copy data to GPU\n    cudaMemcpy(d_arr, arr.data(), n * sizeof(long long), cudaMemcpyHostToDevice);\n    \n    // Launch kernel\n    sum_kernel<<<gridSize, blockSize, blockSize * sizeof(long long)>>>(d_arr, d_partial_sums, n);\n    \n    // Copy partial sums back to host\n    std::vector<long long> partial_sums(gridSize);\n    cudaMemcpy(partial_sums.data(), d_partial_sums, gridSize * sizeof(long long), cudaMemcpyDeviceToHost);\n    \n    // Final reduction on CPU\n    long long total_sum = 0;\n    for (int i = 0; i < gridSize; i++) {\n        total_sum += partial_sums[i];\n    }\n    \n    // Cleanup\n    cudaFree(d_arr);\n    cudaFree(d_partial_sums);\n    \n    return total_sum;\n}",
        "framework": "CUDA"
      }
    },
    {
      "metadata": {
        "task_type": "matrix_multiply",
        "hardware": {
          "cpus": [
            {
              "cores": 12,
              "threads": 32,
              "frequency": "3.6 GHz",
              "available": "True"
            }
          ],
          "gpu": {
            "cuda_cores": 10496,
            "memory": {
              "size": "24 GB",
              "type": "GDDR6X"
            },
            "available": "True"
          }
        },
        "code": "__global__ void matrix_multiply_kernel(const int* A, int* result, int N, int M) {\n    int row = blockIdx.y * blockDim.y + threadIdx.y;\n    int col = blockIdx.x * blockDim.x + threadIdx.x;\n    \n    if (row < N && col < N) {\n        int sum = 0;\n        for (int k = 0; k < M; k++) {\n            sum += A[row * M + k] * A[col * M + k];\n        }\n        result[row * N + col] = sum;\n    }\n}\n\nvoid matrix_multiply(const Matrix& A, int N, int M, Matrix& result) {\n    result.resize(N * N);\n    \n    int* d_A;\n    int* d_result;\n    \n    size_t size_A = N * M * sizeof(int);\n    size_t size_result = N * N * sizeof(int);\n    \n    cudaMalloc(&d_A, size_A);\n    cudaMalloc(&d_result, size_result);\n    \n    cudaMemcpy(d_A, A.data(), size_A, cudaMemcpyHostToDevice);\n    \n    dim3 blockSize(16, 16);\n    dim3 gridSize((N + blockSize.x - 1) / blockSize.x, (N + blockSize.y - 1) / blockSize.y);\n    \n    matrix_multiply_kernel<<<gridSize, blockSize>>>(d_A, d_result, N, M);\n    \n    cudaMemcpy(result.data(), d_result, size_result, cudaMemcpyDeviceToHost);\n    \n    cudaFree(d_A);\n    cudaFree(d_result);\n}",
        "framework": "CUDA"
      }
    },
    {
      "metadata": {
        "task_type": "graph_bfs",
        "hardware": {
          "cpus": [
            {
              "cores": 12,
              "threads": 32,
              "frequency": "3.6 GHz",
              "available": "True"
            }
          ],
          "gpu": {
            "cuda_cores": 10496,
            "memory": {
              "size": "24 GB",
              "type": "GDDR6X"
            },
            "available": "True"
          }
        },
        "code": "__global__ void bfs_kernel(const int* offset, const int* edges, int* distances, bool* visited, bool* frontier, bool* next_frontier, int numVertices, bool* has_work) {\n    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n    \n    if (tid < numVertices && frontier[tid]) {\n        int start = offset[tid];\n        int end = (tid + 1 < numVertices) ? offset[tid + 1] : offset[tid];\n        \n        for (int i = start; i < end; i++) {\n            int neighbor = edges[i];\n            if (!visited[neighbor]) {\n                if (atomicCAS((int*)&visited[neighbor], 0, 1) == 0) {\n                    distances[neighbor] = distances[tid] + 1;\n                    next_frontier[neighbor] = true;\n                    *has_work = true;\n                }\n            }\n        }\n    }\n}\n\nvoid bfs(const CUDAGraph& graph, int start, std::vector<int>& result) {\n    result.resize(graph.numVertices);\n    std::fill(result.begin(), result.end(), -1);\n    result[start] = 0;\n    \n    // Device memory allocation\n    int* d_offset;\n    int* d_edges;\n    int* d_distances;\n    bool* d_visited;\n    bool* d_frontier;\n    bool* d_next_frontier;\n    bool* d_has_work;\n    \n    cudaMalloc(&d_offset, graph.numVertices * sizeof(int));\n    cudaMalloc(&d_edges, graph.numEdges * sizeof(int));\n    cudaMalloc(&d_distances, graph.numVertices * sizeof(int));\n    cudaMalloc(&d_visited, graph.numVertices * sizeof(bool));\n    cudaMalloc(&d_frontier, graph.numVertices * sizeof(bool));\n    cudaMalloc(&d_next_frontier, graph.numVertices * sizeof(bool));\n    cudaMalloc(&d_has_work, sizeof(bool));\n    \n    // Copy graph data to device\n    cudaMemcpy(d_offset, graph.offset, graph.numVertices * sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_edges, graph.edges, graph.numEdges * sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_distances, result.data(), graph.numVertices * sizeof(int), cudaMemcpyHostToDevice);\n    \n    // Initialize arrays\n    cudaMemset(d_visited, false, graph.numVertices * sizeof(bool));\n    cudaMemset(d_frontier, false, graph.numVertices * sizeof(bool));\n    cudaMemset(d_next_frontier, false, graph.numVertices * sizeof(bool));\n    \n    // Set start vertex\n    bool start_visited = true;\n    bool start_frontier = true;\n    cudaMemcpy(&d_visited[start], &start_visited, sizeof(bool), cudaMemcpyHostToDevice);\n    cudaMemcpy(&d_frontier[start], &start_frontier, sizeof(bool), cudaMemcpyHostToDevice);\n    \n    // Calculate grid and block dimensions\n    int blockSize = 256;\n    int gridSize = (graph.numVertices + blockSize - 1) / blockSize;\n    \n    bool has_work = true;\n    while (has_work) {\n        has_work = false;\n        cudaMemcpy(d_has_work, &has_work, sizeof(bool), cudaMemcpyHostToDevice);\n        \n        bfs_kernel<<<gridSize, blockSize>>>(d_offset, d_edges, d_distances, d_visited, d_frontier, d_next_frontier, graph.numVertices, d_has_work);\n        cudaDeviceSynchronize();\n        \n        cudaMemcpy(&has_work, d_has_work, sizeof(bool), cudaMemcpyDeviceToHost);\n        \n        // Swap frontiers\n        bool* temp = d_frontier;\n        d_frontier = d_next_frontier;\n        d_next_frontier = temp;\n        \n        cudaMemset(d_next_frontier, false, graph.numVertices * sizeof(bool));\n    }\n    \n    // Copy results back to host\n    cudaMemcpy(result.data(), d_distances, graph.numVertices * sizeof(int), cudaMemcpyDeviceToHost);\n    \n    // Count reachable vertices\n    int reachable_count = 0;\n    for (int i = 0; i < graph.numVertices; i++) {\n        if (result[i] != -1) {\n            reachable_count++;\n        }\n    }\n    \n    printf(\"Final result size: %d\\n\", reachable_count);\n    \n    // Cleanup\n    cudaFree(d_offset);\n    cudaFree(d_edges);\n    cudaFree(d_distances);\n    cudaFree(d_visited);\n    cudaFree(d_frontier);\n    cudaFree(d_next_frontier);\n    cudaFree(d_has_work);\n}",
        "framework": "CUDA"
      }
    }
  ]
}