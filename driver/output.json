{
  "tasks": [
    {
      "metadata": {
        "task_type": "array_sum",
        "hardware": {
          "cpus": [
            {
              "cores": 8,
              "threads": 16,
              "frequency": "3.6 GHz",
              "available": "True"
            }
          ],
          "gpu": {
            "cuda_cores": 3584,
            "memory": {
              "size": "12 GB",
              "type": "GDDR6"
            },
            "available": "False"
          }
        },
        "code": "#include <vector>\n#include <omp.h>\n\nusing Array = std::vector<int>;\n\nint array_sum(const Array& arr) {\n    int sum = 0;\n    #pragma omp parallel for reduction(+:sum) num_threads(16)\n    for (size_t i = 0; i < arr.size(); ++i) {\n        sum += arr[i];\n    }\n    return sum;\n}",
        "framework": "OpenMP"
      }
    },
    {
      "metadata": {
        "task_type": "matrix_multiply",
        "hardware": {
          "cpus": [
            {
              "cores": 8,
              "threads": 16,
              "frequency": "3.6 GHz",
              "available": "True"
            }
          ],
          "gpu": {
            "cuda_cores": 3584,
            "memory": {
              "size": "12 GB",
              "type": "GDDR6"
            },
            "available": "False"
          }
        },
        "code": "#include <vector>\n#include <omp.h>\nusing Matrix = std::vector<std::vector<int>>;\n\nvoid matrix_multiply(const Matrix& A, Matrix& result) {\n    int n = A.size();\n    #pragma omp parallel for\n    for (int i = 0; i < n; ++i) {\n        for (int j = 0; j < n; ++j) {\n            int sum = 0;\n            for (int k = 0; k < n; ++k) {\n                sum += A[i][k] * A[j][k];\n            }\n            result[i][j] = sum;\n        }\n    }\n}",
        "framework": "OpenMP"
      }
    },
    {
      "metadata": {
        "task_type": "graph_bfs",
        "hardware": {
          "cpus": [
            {
              "cores": 8,
              "threads": 16,
              "frequency": "3.6 GHz",
              "available": "True"
            }
          ],
          "gpu": {
            "cuda_cores": 3584,
            "memory": {
              "size": "12 GB",
              "type": "GDDR6"
            },
            "available": "False"
          }
        },
        "code": "#include <vector>\n#include <atomic>\n#include <algorithm>\n#include <omp.h>\n\nvoid bfs(const Graph& graph, int start, std::vector<int>& result) {\n    std::vector<char> visited(graph.numVertices, 0);\n    std::vector<int> current, next;\n    \n    if (start < 0 || start >= graph.numVertices) return;\n    visited[start] = 1;\n    result.push_back(start);\n    current.push_back(start);\n\n    while (!current.empty()) {\n        next.clear();\n        #pragma omp parallel\n        {\n            std::vector<int> next_local;\n            #pragma omp for\n            for (size_t i = 0; i < current.size(); ++i) {\n                int u = current[i];\n                for (int j = graph.offset[u]; j < graph.offset[u+1]; ++j) {\n                    int v = graph.edges[j];\n                    if (!__atomic_load_n(&visited[v], __ATOMIC_RELAXED)) {\n                        if (__atomic_exchange_n(&visited[v], 1, __ATOMIC_RELAXED) == 0) {\n                            next_local.push_back(v);\n                        }\n                    }\n                }\n            }\n            #pragma omp critical\n            next.insert(next.end(), next_local.begin(), next_local.end());\n        }\n        std::sort(next.begin(), next.end());\n        result.insert(result.end(), next.begin(), next.end());\n        current.swap(next);\n    }\n    \n    for (int node : result) {\n        printf(\"%d \", node);\n    }\n    printf(\"\\n\");\n}",
        "framework": "OpenMP"
      }
    }
  ]
}